{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper libraries\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTS\n",
    "PATH = os.getcwd()\n",
    "DATASET = os.path.join(PATH, \"chest_xray\")\n",
    "TRAINING_DATA = os.path.join(DATASET, \"train\")\n",
    "TESTING_DATA = os.path.join(DATASET, \"test\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "construim lista cu toate pozele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "\n",
    "size = 100\n",
    "def generate_training_data():\n",
    "    images = []\n",
    "    labels = []\n",
    "    for label in os.listdir(TRAINING_DATA):\n",
    "        _path = os.path.join(TRAINING_DATA, label)\n",
    "        for image in os.listdir(_path):\n",
    "            img = load_img(_path + \"/\" + image, target_size=(size,size))\n",
    "            img = img_to_array(img)\n",
    "        \n",
    "            images.append(img)\n",
    "            labels.append(label)\n",
    "    return (images, labels)\n",
    "\n",
    "def generate_testing_data():\n",
    "    images = []\n",
    "    labels = []\n",
    "    for label in os.listdir(TESTING_DATA):\n",
    "        _path = os.path.join(TESTING_DATA, label)\n",
    "        for image in os.listdir(_path):\n",
    "            img = load_img(_path + \"/\" + image, target_size=(size,size))\n",
    "            img = img_to_array(img)\n",
    "            \n",
    "            images.append(img)\n",
    "            labels.append(label)\n",
    "    return (images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(256, activation='relu'),\n",
    "    keras.layers.Dense(2)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "            loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_labels = generate_training_data()\n",
    "test_data, test_labels = generate_testing_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "encoder = LabelBinarizer()\n",
    "train_labels = encoder.fit_transform(train_labels)\n",
    "test_labels = encoder.fit_transform(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5215 samples, validate on 624 samples\n",
      "Epoch 1/20\n",
      "5215/5215 [==============================] - 1s 233us/sample - loss: 278.3267 - accuracy: 0.8449 - val_loss: 99.1446 - val_accuracy: 0.7997\n",
      "Epoch 2/20\n",
      "5215/5215 [==============================] - 1s 158us/sample - loss: 79.4146 - accuracy: 0.8943 - val_loss: 146.6847 - val_accuracy: 0.8013\n",
      "Epoch 3/20\n",
      "5215/5215 [==============================] - 1s 148us/sample - loss: 65.5824 - accuracy: 0.9076 - val_loss: 269.4344 - val_accuracy: 0.7452\n",
      "Epoch 4/20\n",
      "5215/5215 [==============================] - 1s 152us/sample - loss: 25.3552 - accuracy: 0.9475 - val_loss: 188.3806 - val_accuracy: 0.7692\n",
      "Epoch 5/20\n",
      "5215/5215 [==============================] - 1s 151us/sample - loss: 47.9259 - accuracy: 0.9131 - val_loss: 493.7019 - val_accuracy: 0.6667\n",
      "Epoch 6/20\n",
      "5215/5215 [==============================] - 1s 152us/sample - loss: 19.1987 - accuracy: 0.9509 - val_loss: 65.8176 - val_accuracy: 0.8333\n",
      "Epoch 7/20\n",
      "5215/5215 [==============================] - 1s 151us/sample - loss: 29.3386 - accuracy: 0.9225 - val_loss: 74.5939 - val_accuracy: 0.8061\n",
      "Epoch 8/20\n",
      "5215/5215 [==============================] - 1s 151us/sample - loss: 13.1825 - accuracy: 0.9440 - val_loss: 145.9201 - val_accuracy: 0.7003\n",
      "Epoch 9/20\n",
      "5215/5215 [==============================] - 1s 149us/sample - loss: 6.6447 - accuracy: 0.9507 - val_loss: 20.9036 - val_accuracy: 0.8205\n",
      "Epoch 10/20\n",
      "5215/5215 [==============================] - 1s 150us/sample - loss: 6.7917 - accuracy: 0.9386 - val_loss: 32.8590 - val_accuracy: 0.7788\n",
      "Epoch 11/20\n",
      "5215/5215 [==============================] - 1s 149us/sample - loss: 4.2765 - accuracy: 0.9488 - val_loss: 72.8601 - val_accuracy: 0.6715\n",
      "Epoch 12/20\n",
      "5215/5215 [==============================] - 1s 154us/sample - loss: 2.8167 - accuracy: 0.9498 - val_loss: 65.3823 - val_accuracy: 0.6715\n",
      "Epoch 13/20\n",
      "5215/5215 [==============================] - 1s 151us/sample - loss: 1.8764 - accuracy: 0.9549 - val_loss: 14.9401 - val_accuracy: 0.7564\n",
      "Epoch 14/20\n",
      "5215/5215 [==============================] - 1s 150us/sample - loss: 0.8408 - accuracy: 0.9655 - val_loss: 15.3028 - val_accuracy: 0.7308\n",
      "Epoch 15/20\n",
      "5215/5215 [==============================] - 1s 153us/sample - loss: 0.6973 - accuracy: 0.9601 - val_loss: 9.9720 - val_accuracy: 0.7644\n",
      "Epoch 16/20\n",
      "5215/5215 [==============================] - 1s 148us/sample - loss: 0.3732 - accuracy: 0.9695 - val_loss: 8.0104 - val_accuracy: 0.7516\n",
      "Epoch 17/20\n",
      "5215/5215 [==============================] - 1s 151us/sample - loss: 0.2549 - accuracy: 0.9584 - val_loss: 1.0247 - val_accuracy: 0.7756\n",
      "Epoch 18/20\n",
      "5215/5215 [==============================] - 1s 154us/sample - loss: 0.9622 - accuracy: 0.9607 - val_loss: 1.6228 - val_accuracy: 0.7212\n",
      "Epoch 19/20\n",
      "5215/5215 [==============================] - 1s 155us/sample - loss: 0.0777 - accuracy: 0.9712 - val_loss: 1.5063 - val_accuracy: 0.7516\n",
      "Epoch 20/20\n",
      "5215/5215 [==============================] - 1s 149us/sample - loss: 0.0743 - accuracy: 0.9714 - val_loss: 1.1150 - val_accuracy: 0.7756\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1dc391d6048>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=np.array(train_data), \n",
    "        y=np.array(train_labels),  \n",
    "        epochs=20,\n",
    "        validation_data=(np.array(test_data),np.array(test_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
